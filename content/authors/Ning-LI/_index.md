
---
# Display name

# Format: Your_given_name Your_surname 

title: Ning Li

# Username

# Format: this should match the folder name

authors:

- Ning LI

# Is this the primary user of the site?

# no need to modify 

superuser: false

# Role/position

# other options like PhD student, Post-doctoral Fellow or Research Assistant, e.g..

role: Post-doctoral Fellow

# Organizations/Affiliations

organizations:

- name: The Hong Kong Polytechnic University
  url: ""

interests:

- Edge Intelligence
- Edge Large Language Model
- Edge computing

education:
  courses:

  - course: PhD in Computer Science
    institution: Universidad Politecnica de Madrid, Madrid, Spain
    year: 2014-2018
  - course: MEng in Computer Science
    institution: Zhengzhou University, Zhengzhou, China
    year: 2011-2024
  - course: BSc in Biotechnology
    institution: Zhengzhou University, Zhengzhou, China
    year: 2007-2011

# Social/Academic Networking

# To disable, comment blew lines with `#`.

social:

# - icon: google-scholar

#  icon_pack: ai

#  link: https://scholar.google.co.uk/citations?user=sIwtMXoAAAAJ

# - icon: github

#  icon_pack: fab

#  link: https://github.com/gcushen

# To enable, copy your cv to cv-your_given_name-your_surname/cv.pdf". To disable, comment blew lines with `#`.

#- icon: cv

#  icon_pack: ai

#  link: resume/cv-andrew-ng/cv.pdf

# Choose which group that you belong to

#  available groups:

#  - Director (Head of Lab)

#  - Research Staffs (RA, Postdoc, RAP, e.g.)

#  - Research Students (Master/PhD student, e.g.)

#  - Visitors (Visiting prof/student, e.g.)

#  - Previous Members (Alumni)

user_groups:

- Research Staffs

---

Ning Li (李宁) is a Postdoc in the department of Computing (COMP) at The Hong Kong Polytechnic University, supervised by Prof. Song Guo. Before that, he received the PhD from the School of Computer Science, Universidad Politecnica de Madrid, Madrid, Spain, in 2018.

His research interest broadly lies in the areas of edge intelligence, edge LLM, edge computing, etc. Some specific topics such as split learning, distributed learning, model compression, and MoE are highly involved.

---
